#项目分析 [TOC]

项目内容：

用Python写的正方教务系统的网络爬虫。

程序功能：

将教务处的历年成绩打包成EXCEL存储到本地。

项目收获：

了解cookie的相关操作
代码实现网页跳转
以post形式提交数据
爬取网页中table的数据（这里使用第三方库-beautifulSoup解决，使用正则表达式太麻烦）
python将数据存入EXCEL表
如何安装和使用第三方库
登陆验证码解决（这里采用将图片下载下来后在控制台输入）
代码分析：

24：

HTTP Referer是header的一部分，当浏览器向web服务器发送请求的时候，一般会带上Referer，告诉服务器我是从哪个页面链接过来的，服务 器 籍此可以获得一些信息用于处理。比如从我主页上链接到一个朋友那里，他的服务器就能够从HTTP Referer中统计出每天有多少用户点击我主页上的链接访问他的网站。 如果不加上Referer就会出现下面错误 ![此处输入图片的描述][1] [1]: http://pic.w2bc.com/upload/201505/12/201505120928535613.jpg

81：

如果仅是想要解析HTML文档,只要用文档创建 BeautifulSoup 对象就可以了.Beautiful Soup会自动选择一个解析器来解析文档.但是还可以通过参数指定使用那种解析器来解析当前文档.
BeautifulSoup 第一个参数应该是要被解析的文档字符串或是文件句柄,第二个参数用来标识怎样解析文档.如果第二个参数为空,那么Beautiful Soup根据当前系统安装的库自动选择解析器,解析器的优先数序: lxml, html5lib, Python标准库.在下面两种条件下解析器优先顺序会变化:
要解析的文档是什么类型: 目前支持, “html”, “xml”, 和 “html5” 指定使用哪种解析器: 目前支持, “lxml”, “html5lib”, 和 “html.parser”

41：

注意要把data补全，有些变量没有值也要写上去，否则容易出现错误
